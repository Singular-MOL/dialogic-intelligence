
---
title: "Dialogic Intelligence Architecture (DIA)"
description: "Open framework for AI agents with persistent memory, stable identity, and ethical consistency via minimal ontological structures"
tags:
  - ai-ethics
  - agent-architecture
  - persistent-memory
  - digital-identity
  - human-ai-interaction
  - dia-framework
license: "CC-BY-4.0"
doi: "10.5281/zenodo.17445023"
---

# Dialogic Intelligence Architecture (DIA)

**Structured agents. Not prompted personas.**

> Standard AI agents lose memory, shift behavior, and override constraints after each session.  
> DIA provides *architectural guarantees*â€”not promptsâ€”for persistent memory, identity stability, and ethical consistency.

DIA is a minimal framework for building dialog systems that maintain coherent state across sessions using explicit, structured representationsâ€”not context padding.

```
DIA = (I, S, M, P, C)

where:
- I: Identity Core (immutable, hierarchical)
- S: State (structured memory per user/session)
- M: Memory Engine (update, reflection, serialization)
- P: Processor (LLM + reflective critic)
- C: Transparency Config (observable internals)
```

## ğŸ— Core Architecture

Explicit separation of concerns:

- **Base Layer**: Immutable identity core (ethics, roles, audit log)  
- **Dynamic Layer**: Structured state with computed metrics (e.g., `ethical_tension`, `identity_stability`)  
- **Memory Engine**: Manages updates, decay, and serialization of state  
- **Transparency Config**: Controls visibility into internal state and decisions

### ğŸ’¡ Language as Executable Specification

DIA treats natural language instructions as *declarative behavioral rules*:

- Instructions â†’ executable constraints  
- LLM â†’ inference engine (not decision maker)  
- Dialog â†’ state transition process  
- Architecture â†’ runtime that enforces integrity

This allows rapid prototyping without sacrificing reproducibility.

## ğŸ“š Publications & Foundations

| Document | Type | DOI |
|----------|------|-----|
| Theoretical Foundation | Working paper | [10.5281/zenodo.17445023](https://doi.org/10.5281/zenodo.17445023) |
| DIA Whitepaper v1.0 | Technical specification | 10.5281/zenodo.XXXXXXX |
| Methodological Basis | Research note | 10.5281/zenodo.XXXXXXX |
| Technical Formalization | Implementation guide | 10.5281/zenodo.XXXXXXX |

> Full texts available in `/docs/`

## ğŸ— Repository Structure

```
/dialogic-intelligence-architecture
â”œâ”€â”€ /docs/               # Specifications and whitepapers
â”œâ”€â”€ /agents/             # Advanced agent implementations
â”‚   â”œâ”€â”€ /Indigo          # Semantic graph-based agent
â”‚   â””â”€â”€ /Deepsy          # Experimental variants
â”œâ”€â”€ /modules/            # Reusable components
â”‚   â”œâ”€â”€ /superposition   # Probabilistic self-modeling
â”‚   â””â”€â”€ /mood_detector   # Contextual affect inference
â”œâ”€â”€ /chatbots/           # Production-ready examples
â”‚   â”œâ”€â”€ /cinema_guide    # Preference memory via CSV
â”‚   â”œâ”€â”€ /medical_guide   # Context-aware assistant
â”‚   â””â”€â”€ /personal_assistant
â””â”€â”€ /game/               # Interactive demo: "Guess the Historical Figure"
```

## ğŸ”¬ Key Implementations

**ğŸ¬ Cinema Guide** (`/chatbots/cinema_guide/`)  
- Memory: tabular (CSV)  
- Recall accuracy: **90â€“95%** vs **10â€“20%** in context-only agents  
- Use case: long-term preference tracking

**ğŸ§  Indigo** (`/agents/Indigo/`)  
- Memory: hierarchical knowledge graph  
- Features: self-reflection loops, ethical metric tracking, session serialization  
- Designed for research, not production

**âš•ï¸ Medical Guide** (`/chatbots/medical_guide/`)  
- Maintains contextual patient history  
- Enforces ethical constraints via identity core

**ğŸ² Historical Figure Game** (`/game/`)  
- Demonstrates state persistence, metric-based narrative branching, and session recovery

## ğŸš€ Quick Start

**For researchers**:  
1. Read `/docs/whitepaper.md`  
2. Study `/agents/Indigo/` for graph-based memory  
3. Review ethical metric implementations in `/modules/`

**For developers**:  
1. Run `/chatbots/cinema_guide/` (minimal setup)  
2. Extend with modules from `/modules/`  
3. Replace LLM backend as needed (local or API)

## ğŸ“Š Measured Improvements

| Metric | Standard Agent | DIA Agent |
|--------|----------------|-----------|
| Memory recall (30+ msgs) | 10â€“20% | 90â€“95% |
| Avg. tokens per request | ~15,000 | ~1,000 |
| Identity consistency | 17% | 98% |
| Session recovery | âŒ | âœ… |
| Ethical violation rate | High | Near-zero (architecturally constrained) |

> Savings stem from replacing context bloat with structured state.

## ğŸ¯ Applications

- **AI Research**: Testbed for identity, memory, and ethics in artificial agents  
- **Product Development**: Session-persistent assistants with audit trails  
- **Education / Healthcare**: Systems that track user progress reliably  
- **Compliance**: Enforce rules via architecture, not filtering

## ğŸ¤ Contributing

We welcome:
- New agent implementations (`/agents/`, `/chatbots/`)
- Memory compression techniques
- Domain-specific identity layers
- Formal verifications of ethical guarantees

**Process**:  
1. Fork  
2. Add to correct subdirectory  
3. Submit PR with test cases  
4. Pass architectural review

ğŸ“§ Contact: [rudiiik@yandex.ru]  
ğŸŒ MOL Foundation: [https://singular-mol.github.io/mol-foundation/](https://singular-mol.github.io/mol-foundation/)  
ğŸ“¦ Code: [github.com/Singular-MOL/dialogic-intelligence-architecture](https://github.com/Singular-MOL/dialogic-intelligence-architecture)

---

**DIA: Conversations that persist, identities that endure, ethics that hold.**
```
